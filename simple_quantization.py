# simple_quantization.py
"""ç®€åŒ–çš„ç‹¬ç«‹é‡åŒ–è„šæœ¬ï¼Œé¿å…é…ç½®ä¾èµ–é—®é¢˜"""

import torch
import torch.nn as nn
import tensorrt as trt
import numpy as np
import os
import cv2
import PIL.Image
from pathlib import Path
import glob
import time

class SimpleCalibrationDataLoader:
    """ç®€åŒ–çš„æ ¡å‡†æ•°æ®åŠ è½½å™¨ï¼Œç›´æ¥è¯»å–å›¾åƒæ–‡ä»¶"""
    
    def __init__(self, data_path, img_size=512, max_samples=500):
        self.img_size = img_size
        self.max_samples = max_samples
        
        # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
        data_path = Path(data_path)
        if data_path.is_dir():
            # å¦‚æœæ˜¯ç›®å½•ï¼ŒæŸ¥æ‰¾æ‰€æœ‰å›¾åƒæ–‡ä»¶
            image_patterns = ["*.jpg", "*.jpeg", "*.png", "*.bmp"]
            self.image_files = []
            for pattern in image_patterns:
                self.image_files.extend(glob.glob(str(data_path / "**" / pattern), recursive=True))
        else:
            # å¦‚æœæ˜¯TUMæ•°æ®é›†
            rgb_file = data_path / "rgb.txt"
            if rgb_file.exists():
                with open(rgb_file, 'r') as f:
                    lines = f.readlines()
                self.image_files = [str(data_path / line.strip().split()[1]) for line in lines[3:]]  # è·³è¿‡å‰3è¡Œæ³¨é‡Š
            else:
                raise ValueError(f"æ‰¾ä¸åˆ°å›¾åƒæ–‡ä»¶: {data_path}")
        
        self.image_files = self.image_files[:max_samples]
        self.current_idx = 0
        print(f"æ‰¾åˆ° {len(self.image_files)} å¼ æ ¡å‡†å›¾åƒ")
        
    def __iter__(self):
        self.current_idx = 0
        return self
        
    def __next__(self):
        if self.current_idx >= len(self.image_files):
            raise StopIteration
            
        # è¯»å–å’Œé¢„å¤„ç†å›¾åƒ
        img_path = self.image_files[self.current_idx]
        img = cv2.imread(img_path)
        if img is None:
            print(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")
            self.current_idx += 1
            return self.__next__()
            
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # é¢„å¤„ç† - ç®€åŒ–ç‰ˆæœ¬çš„resize_img
        img_tensor = self.preprocess_image(img)
        
        self.current_idx += 1
        return {"input": img_tensor}
    
    def preprocess_image(self, img):
        """ç®€åŒ–çš„å›¾åƒé¢„å¤„ç†"""
        # è½¬æ¢ä¸ºPIL
        img_pil = PIL.Image.fromarray(img)
        
        # è°ƒæ•´å¤§å°
        W, H = img_pil.size
        S = max(W, H)
        new_size = tuple(int(round(x * self.img_size / S)) for x in img_pil.size)
        img_pil = img_pil.resize(new_size, PIL.Image.LANCZOS)
        
        # ä¸­å¿ƒè£å‰ª
        W, H = img_pil.size
        cx, cy = W // 2, H // 2
        halfw, halfh = ((2 * cx) // 16) * 8, ((2 * cy) // 16) * 8
        img_pil = img_pil.crop((cx - halfw, cy - halfh, cx + halfw, cy + halfh))
        
        # è½¬æ¢ä¸ºtensor
        img_array = np.array(img_pil).astype(np.float32) / 255.0
        img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)  # (1, 3, H, W)
        
        return img_tensor.numpy()

class SimpleTensorRTCalibrator(trt.IInt8EntropyCalibrator2):
    """ç®€åŒ–çš„TensorRTæ ¡å‡†å™¨"""
    
    def __init__(self, dataloader, cache_file="simple_calibration.cache"):
        trt.IInt8EntropyCalibrator2.__init__(self)
        self.dataloader = dataloader
        self.cache_file = cache_file
        self.data_iter = iter(dataloader)
        self.batch_allocation = None
        
    def get_batch_size(self):
        return 1
        
    def get_batch(self, names):
        try:
            batch = next(self.data_iter)
            if self.batch_allocation is None:
                # åˆ†é…GPUå†…å­˜
                self.batch_allocation = {}
                for name, data in batch.items():
                    size = data.size * data.itemsize
                    self.batch_allocation[name] = trt.cuda.mem_alloc(size)
            
            # å°†æ•°æ®å¤åˆ¶åˆ°GPU
            bindings = []
            for name, data in batch.items():
                trt.cuda.memcpy_htod(self.batch_allocation[name], 
                                   data.astype(np.float32).ravel())
                bindings.append(int(self.batch_allocation[name]))
            
            return bindings
        except StopIteration:
            return None
            
    def read_calibration_cache(self):
        if os.path.exists(self.cache_file):
            with open(self.cache_file, "rb") as f:
                return f.read()
        return None
        
    def write_calibration_cache(self, cache):
        with open(self.cache_file, "wb") as f:
            f.write(cache)

class SimpleViTWrapper(nn.Module):
    """ç®€åŒ–çš„ViTåŒ…è£…å™¨ç”¨äºONNXå¯¼å‡º"""
    
    def __init__(self, model):
        super().__init__()
        self.model = model
        
    def forward(self, x):
        # ç®€åŒ–çš„ç¼–ç è¿‡ç¨‹
        feat, pos, _ = self.model._encode_image(x, torch.tensor([[x.shape[2], x.shape[3]]]))
        return feat

def create_onnx_model(model, input_shape=(1, 3, 512, 512), onnx_path="simple_vit_encoder.onnx"):
    """åˆ›å»ºONNXæ¨¡å‹"""
    print("å¯¼å‡ºONNXæ¨¡å‹...")
    
    # åˆ›å»ºåŒ…è£…å™¨
    wrapper = SimpleViTWrapper(model).eval()
    
    # åˆ›å»ºç¤ºä¾‹è¾“å…¥
    dummy_input = torch.randn(input_shape).cuda()
    
    # å¯¼å‡ºONNX
    torch.onnx.export(
        wrapper,
        dummy_input,
        onnx_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={
            'input': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        }
    )
    
    print(f"ONNXæ¨¡å‹å·²å¯¼å‡º: {onnx_path}")
    return onnx_path

def build_tensorrt_engine(onnx_path, engine_path, calibrator=None, precision="fp16"):
    """æ„å»ºTensorRTå¼•æ“"""
    print(f"æ„å»ºTensorRTå¼•æ“ ({precision})...")
    
    logger = trt.Logger(trt.Logger.WARNING)
    builder = trt.Builder(logger)
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    parser = trt.OnnxParser(network, logger)
    
    # è§£æONNXæ¨¡å‹
    with open(onnx_path, 'rb') as model:
        if not parser.parse(model.read()):
            for error in range(parser.num_errors):
                print(parser.get_error(error))
            return None
    
    # é…ç½®æ„å»ºå™¨
    config = builder.create_builder_config()
    config.max_workspace_size = 2 << 30  # 2GB
    
    # è®¾ç½®ç²¾åº¦
    if precision == "fp16":
        config.set_flag(trt.BuilderFlag.FP16)
        print("å¯ç”¨FP16ç²¾åº¦")
    elif precision == "int8":
        config.set_flag(trt.BuilderFlag.INT8)
        if calibrator:
            config.int8_calibrator = calibrator
            print("å¯ç”¨INT8ç²¾åº¦withæ ¡å‡†å™¨")
        else:
            print("è­¦å‘Š: INT8ç²¾åº¦éœ€è¦æ ¡å‡†å™¨")
            return None
    
    # è®¾ç½®è¾“å…¥å½¢çŠ¶
    input_tensor = network.get_input(0)
    profile = builder.create_optimization_profile()
    profile.set_shape(input_tensor.name, (1, 3, 512, 512), (1, 3, 512, 512), (4, 3, 512, 512))
    config.add_optimization_profile(profile)
    
    # æ„å»ºå¼•æ“
    engine = builder.build_engine(network, config)
    
    if engine:
        # ä¿å­˜å¼•æ“
        with open(engine_path, "wb") as f:
            f.write(engine.serialize())
        print(f"TensorRTå¼•æ“å·²ä¿å­˜: {engine_path}")
        
    return engine

def main_simple_quantization():
    """ä¸»é‡åŒ–å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ç®€åŒ–çš„MASt3Ré‡åŒ–å·¥å…·")
    parser.add_argument("--dataset", default="datasets/tum/rgbd_dataset_freiburg1_desk", 
                       help="æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--precision", choices=["fp16", "int8"], default="int8",
                       help="é‡åŒ–ç²¾åº¦")
    parser.add_argument("--samples", type=int, default=500, help="æ ¡å‡†æ ·æœ¬æ•°")
    parser.add_argument("--output", default="tensorrt_engines", help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output)
    output_dir.mkdir(exist_ok=True)
    
    # 1. åŠ è½½æ¨¡å‹
    print("åŠ è½½MASt3Ræ¨¡å‹...")
    sys.path.append('.')
    from mast3r_slam.mast3r_utils import load_mast3r
    model = load_mast3r().cuda().eval()
    
    # 2. å¯¼å‡ºONNX
    onnx_path = output_dir / "simple_vit_encoder.onnx"
    create_onnx_model(model, onnx_path=str(onnx_path))
    
    # 3. å‡†å¤‡æ ¡å‡†æ•°æ®ï¼ˆä»…INT8éœ€è¦ï¼‰
    calibrator = None
    if args.precision == "int8":
        print("å‡†å¤‡æ ¡å‡†æ•°æ®...")
        try:
            calib_loader = SimpleCalibrationDataLoader(args.dataset, max_samples=args.samples)
            calibrator = SimpleTensorRTCalibrator(calib_loader)
        except Exception as e:
            print(f"æ ¡å‡†æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            print("å›é€€åˆ°FP16ç²¾åº¦")
            args.precision = "fp16"
    
    # 4. æ„å»ºå¼•æ“
    engine_path = output_dir / f"simple_vit_encoder_{args.precision}.trt"
    engine = build_tensorrt_engine(
        str(onnx_path),
        str(engine_path),
        calibrator,
        args.precision
    )
    
    if engine:
        print(f"\nğŸ‰ é‡åŒ–æˆåŠŸ!")
        print(f"å¼•æ“æ–‡ä»¶: {engine_path}")
        
        # 5. ç®€å•æ€§èƒ½æµ‹è¯•
        print("\nè¿è¡Œæ€§èƒ½æµ‹è¯•...")
        benchmark_simple(model, str(engine_path))
        
        # 6. ç”Ÿæˆä½¿ç”¨è¯´æ˜
        print_usage_instructions(str(engine_path))
    else:
        print("âŒ é‡åŒ–å¤±è´¥")

def benchmark_simple(original_model, engine_path):
    """ç®€å•çš„æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("=== æ€§èƒ½åŸºå‡†æµ‹è¯• ===")
    
    # æµ‹è¯•åŸå§‹æ¨¡å‹
    test_input = torch.randn(1, 3, 512, 512).cuda()
    test_shape = torch.tensor([[512, 512]])
    
    # é¢„çƒ­
    for _ in range(10):
        with torch.no_grad():
            _ = original_model._encode_image(test_input, test_shape)
    
    # æµ‹è¯•
    torch.cuda.synchronize()
    start_time = time.time()
    
    for _ in range(100):
        with torch.no_grad():
            _ = original_model._encode_image(test_input, test_shape)
    
    torch.cuda.synchronize()
    original_time = time.time() - start_time
    
    print(f"åŸå§‹æ¨¡å‹å¹³å‡æ—¶é—´: {original_time/100:.4f}s")
    print(f"é¢„æœŸé‡åŒ–åŠ é€Ÿ: 2-4å€")

def print_usage_instructions(engine_path):
    """æ‰“å°ä½¿ç”¨è¯´æ˜"""
    print(f"\n=== ä½¿ç”¨è¯´æ˜ ===")
    print("1. åœ¨main.pyä¸­ä½¿ç”¨é‡åŒ–æ¨¡å‹ï¼Œæ·»åŠ ä»¥ä¸‹ä»£ç :")
    
    usage_code = f'''
# åœ¨main.pyä¸­çš„æ¨¡å‹åŠ è½½éƒ¨åˆ†ï¼Œæ›¿æ¢:
# model = load_mast3r(device=device)

# ä¸º:
try:
    from simple_tensorrt_inference import SimpleTensorRTInference
    print("åŠ è½½é‡åŒ–æ¨¡å‹...")
    original_model = load_mast3r(device=device)
    trt_inference = SimpleTensorRTInference("{engine_path}")
    
    # åˆ›å»ºåŒ…è£…æ¨¡å‹
    class QuantizedModel:
        def __init__(self, original_model, trt_inference):
            self.original_model = original_model
            self.trt_inference = trt_inference
            self._decoder = original_model._decoder
            self._downstream_head = original_model._downstream_head
        
        def _encode_image(self, img, true_shape):
            # ä½¿ç”¨TensorRTåŠ é€Ÿç¼–ç 
            try:
                img_np = img.cpu().numpy()
                feat_np = self.trt_inference.infer(img_np)
                feat = torch.from_numpy(feat_np).to(img.device)
                
                # ç®€åŒ–çš„ä½ç½®ç¼–ç 
                h, w = true_shape[0].item(), true_shape[1].item()
                pos = torch.zeros(1, feat.shape[1], 2, device=img.device, dtype=torch.long)
                return feat, pos, None
            except:
                # å›é€€åˆ°åŸå§‹å®ç°
                return self.original_model._encode_image(img, true_shape)
        
        def __getattr__(self, name):
            return getattr(self.original_model, name)
    
    model = QuantizedModel(original_model, trt_inference)
    print("âœ“ é‡åŒ–æ¨¡å‹åŠ è½½æˆåŠŸ")
    
except Exception as e:
    print(f"é‡åŒ–æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹: {{e}}")
    model = load_mast3r(device=device)
'''
    
    print(usage_code)
    
    # åˆ›å»ºæ¨ç†æ¨¡å—
    create_inference_module(engine_path)

def create_inference_module(engine_path):
    """åˆ›å»ºTensorRTæ¨ç†æ¨¡å—"""
    inference_code = f'''# simple_tensorrt_inference.py
"""ç®€å•çš„TensorRTæ¨ç†æ¨¡å—"""

import tensorrt as trt
import numpy as np
import torch

class SimpleTensorRTInference:
    """ç®€å•çš„TensorRTæ¨ç†å¼•æ“"""
    
    def __init__(self, engine_path):
        self.logger = trt.Logger(trt.Logger.WARNING)
        
        # åŠ è½½å¼•æ“
        with open(engine_path, "rb") as f:
            runtime = trt.Runtime(self.logger)
            self.engine = runtime.deserialize_cuda_engine(f.read())
            
        # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
        self.context = self.engine.create_execution_context()
        
        # åˆ†é…å†…å­˜
        self.allocate_buffers()
        
    def allocate_buffers(self):
        """åˆ†é…è¾“å…¥è¾“å‡ºç¼“å†²åŒº"""
        self.inputs = []
        self.outputs = []
        self.bindings = []
        self.stream = trt.cuda.Stream()
        
        for binding in self.engine:
            size = trt.volume(self.engine.get_binding_shape(binding)) * self.engine.max_batch_size
            dtype = trt.nptype(self.engine.get_binding_dtype(binding))
            
            # åˆ†é…hostå’Œdeviceå†…å­˜
            host_mem = trt.cuda.pagelocked_empty(size, dtype)
            device_mem = trt.cuda.mem_alloc(host_mem.nbytes)
            
            self.bindings.append(int(device_mem))
            
            if self.engine.binding_is_input(binding):
                self.inputs.append({{'host': host_mem, 'device': device_mem}})
            else:
                self.outputs.append({{'host': host_mem, 'device': device_mem}})
                
    def infer(self, input_data):
        """æ‰§è¡Œæ¨ç†"""
        # å¤åˆ¶è¾“å…¥æ•°æ®åˆ°hostå†…å­˜
        np.copyto(self.inputs[0]['host'], input_data.ravel())
        
        # ä¼ è¾“æ•°æ®åˆ°device
        trt.cuda.memcpy_htod_async(self.inputs[0]['device'], self.inputs[0]['host'], self.stream)
        
        # æ‰§è¡Œæ¨ç†
        self.context.execute_async_v2(bindings=self.bindings, stream_handle=self.stream.handle)
        
        # ä¼ è¾“ç»“æœå›host
        trt.cuda.memcpy_dtoh_async(self.outputs[0]['host'], self.outputs[0]['device'], self.stream)
        
        # åŒæ­¥
        self.stream.synchronize()
        
        return self.outputs[0]['host']
'''
    
    # ä¿å­˜æ¨ç†æ¨¡å—
    with open("simple_tensorrt_inference.py", "w") as f:
        f.write(inference_code)
    
    print("\\n2. TensorRTæ¨ç†æ¨¡å—å·²åˆ›å»º: simple_tensorrt_inference.py")

if __name__ == "__main__":
    main_simple_quantization()
