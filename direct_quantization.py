# direct_quantization.py
"""ç›´æ¥å¯ç”¨çš„é‡åŒ–è„šæœ¬ï¼Œé¿å…æ‰€æœ‰é…ç½®é—®é¢˜"""

import torch
import torch.nn as nn
import numpy as np
import os
import sys
from pathlib import Path
import time
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

def load_model_direct():
    """ç›´æ¥åŠ è½½æ¨¡å‹ï¼Œé¿å…é…ç½®é—®é¢˜"""
    print("ç›´æ¥åŠ è½½MASt3Ræ¨¡å‹...")
    
    # ç›´æ¥å¯¼å…¥å’ŒåŠ è½½
    from mast3r.model import AsymmetricMASt3R
    
    model_path = "checkpoints/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth"
    model = AsymmetricMASt3R.from_pretrained(model_path).cuda().eval()
    
    print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
    return model

def create_calibration_data(dataset_path, num_samples=100):
    """åˆ›å»ºæ ¡å‡†æ•°æ®ï¼Œç›´æ¥è¯»å–å›¾åƒ"""
    print(f"å‡†å¤‡æ ¡å‡†æ•°æ®ä»: {dataset_path}")
    
    # è¯»å–TUMæ•°æ®é›†
    rgb_file = Path(dataset_path) / "rgb.txt"
    if not rgb_file.exists():
        raise ValueError(f"æ‰¾ä¸åˆ°rgb.txtæ–‡ä»¶: {rgb_file}")
    
    # è¯»å–å›¾åƒè·¯å¾„
    with open(rgb_file, 'r') as f:
        lines = f.readlines()
    
    image_paths = []
    for line in lines[3:]:  # è·³è¿‡å‰3è¡Œæ³¨é‡Š
        parts = line.strip().split()
        if len(parts) >= 2:
            img_path = Path(dataset_path) / parts[1]
            if img_path.exists():
                image_paths.append(img_path)
    
    # é™åˆ¶æ ·æœ¬æ•°é‡
    image_paths = image_paths[:num_samples]
    print(f"æ‰¾åˆ° {len(image_paths)} å¼ æ ¡å‡†å›¾åƒ")
    
    # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
    calibration_data = []
    for i, img_path in enumerate(image_paths):
        if i % 50 == 0:
            print(f"å¤„ç†æ ¡å‡†å›¾åƒ {i+1}/{len(image_paths)}")
        
        try:
            import cv2
            img = cv2.imread(str(img_path))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # ç®€å•çš„é¢„å¤„ç†
            img_tensor = preprocess_simple(img)
            calibration_data.append(img_tensor)
            
        except Exception as e:
            print(f"è·³è¿‡å›¾åƒ {img_path}: {e}")
            continue
    
    print(f"æˆåŠŸå¤„ç† {len(calibration_data)} å¼ æ ¡å‡†å›¾åƒ")
    return calibration_data

def preprocess_simple(img):
    """ç®€å•çš„å›¾åƒé¢„å¤„ç†"""
    import cv2
    
    # è°ƒæ•´å¤§å°åˆ°512x512
    img_resized = cv2.resize(img, (512, 512))
    
    # å½’ä¸€åŒ–åˆ°[0,1]
    img_norm = img_resized.astype(np.float32) / 255.0
    
    # è½¬æ¢ä¸ºCHWæ ¼å¼
    img_tensor = torch.from_numpy(img_norm).permute(2, 0, 1).unsqueeze(0)  # (1, 3, H, W)
    
    return img_tensor

def export_to_onnx(model, output_path="vit_encoder_direct.onnx"):
    """å¯¼å‡ºæ¨¡å‹åˆ°ONNX"""
    print("å¯¼å‡ºONNXæ¨¡å‹...")
    
    class DirectViTWrapper(nn.Module):
        def __init__(self, model):
            super().__init__()
            self.model = model
            
        def forward(self, x):
            # ç›´æ¥è°ƒç”¨ç¼–ç éƒ¨åˆ†
            try:
                feat, pos, _ = self.model._encode_image(x, torch.tensor([[512, 512]]))
                return feat
            except:
                # å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨æ›´ç›´æ¥çš„æ–¹æ³•
                return self.model.patch_embed(x)
    
    wrapper = DirectViTWrapper(model).eval()
    dummy_input = torch.randn(1, 3, 512, 512).cuda()
    
    # å¯¼å‡ºONNX
    torch.onnx.export(
        wrapper,
        dummy_input,
        output_path,
        export_params=True,
        opset_version=11,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}
    )
    
    print(f"âœ“ ONNXæ¨¡å‹å·²å¯¼å‡º: {output_path}")
    return output_path

def quantize_with_tensorrt(onnx_path, calibration_data, precision="int8", output_path=None):
    """ä½¿ç”¨TensorRTè¿›è¡Œé‡åŒ–"""
    import tensorrt as trt
    
    print(f"å¼€å§‹TensorRT {precision.upper()} é‡åŒ–...")
    
    # åˆ›å»ºcalibrator
    calibrator = None
    if precision == "int8" and calibration_data:
        calibrator = create_calibrator(calibration_data)
    
    # TensorRT builder
    logger = trt.Logger(trt.Logger.WARNING)
    builder = trt.Builder(logger)
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    parser = trt.OnnxParser(network, logger)
    
    # è§£æONNX
    with open(onnx_path, 'rb') as model:
        if not parser.parse(model.read()):
            print("ONNXè§£æå¤±è´¥:")
            for error in range(parser.num_errors):
                print(parser.get_error(error))
            return None
    
    # é…ç½®
    config = builder.create_builder_config()
    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 2 << 30)
    
    # è®¾ç½®ç²¾åº¦
    if precision == "fp16":
        config.set_flag(trt.BuilderFlag.FP16)
    elif precision == "int8" and calibrator:
        config.set_flag(trt.BuilderFlag.INT8)
        config.int8_calibrator = calibrator
    
    # è®¾ç½®è¾“å…¥å½¢çŠ¶
    input_tensor = network.get_input(0)
    profile = builder.create_optimization_profile()
    profile.set_shape(input_tensor.name, (1, 3, 512, 512), (1, 3, 512, 512), (4, 3, 512, 512))
    config.add_optimization_profile(profile)
    
    # æ„å»ºå¼•æ“
    print("æ„å»ºTensorRTå¼•æ“...")
    engine = builder.build_engine(network, config)
    
    if engine:
        if output_path is None:
            output_path = f"mast3r_vit_{precision}.trt"
        
        with open(output_path, "wb") as f:
            f.write(engine.serialize())
        
        print(f"âœ“ TensorRTå¼•æ“å·²ä¿å­˜: {output_path}")
        return output_path
    else:
        print("âŒ TensorRTå¼•æ“æ„å»ºå¤±è´¥")
        return None

def create_calibrator(calibration_data):
    """åˆ›å»ºæ ¡å‡†å™¨"""
    import tensorrt as trt
    
    class SimpleCalibrator(trt.IInt8EntropyCalibrator2):
        def __init__(self, data):
            trt.IInt8EntropyCalibrator2.__init__(self)
            self.data = data
            self.current = 0
            self.device_input = None
            
        def get_batch_size(self):
            return 1
            
        def get_batch(self, names):
            if self.current >= len(self.data):
                return None
                
            # åˆ†é…GPUå†…å­˜
            if self.device_input is None:
                self.device_input = trt.cuda.mem_alloc(self.data[0].numel() * 4)  # float32
            
            # å¤åˆ¶æ•°æ®åˆ°GPU
            batch = self.data[self.current].numpy().astype(np.float32)
            trt.cuda.memcpy_htod(self.device_input, batch)
            
            self.current += 1
            return [int(self.device_input)]
            
        def read_calibration_cache(self):
            cache_file = "direct_calibration.cache"
            if os.path.exists(cache_file):
                with open(cache_file, "rb") as f:
                    return f.read()
            return None
            
        def write_calibration_cache(self, cache):
            cache_file = "direct_calibration.cache"
            with open(cache_file, "wb") as f:
                f.write(cache)
    
    return SimpleCalibrator(calibration_data)

def benchmark_original_model(model, num_iterations=50):
    """æµ‹è¯•åŸå§‹æ¨¡å‹æ€§èƒ½"""
    print("æµ‹è¯•åŸå§‹æ¨¡å‹æ€§èƒ½...")
    
    test_input = torch.randn(1, 3, 512, 512).cuda()
    test_shape = torch.tensor([[512, 512]])
    
    # é¢„çƒ­
    for _ in range(10):
        with torch.no_grad():
            try:
                _ = model._encode_image(test_input, test_shape)
            except:
                # å¦‚æœ_encode_imageå¤±è´¥ï¼Œç›´æ¥ç”¨patch_embed
                _ = model.patch_embed(test_input)
    
    # æµ‹è¯•
    torch.cuda.synchronize()
    start_time = time.time()
    
    for _ in range(num_iterations):
        with torch.no_grad():
            try:
                _ = model._encode_image(test_input, test_shape)
            except:
                _ = model.patch_embed(test_input)
    
    torch.cuda.synchronize()
    total_time = time.time() - start_time
    
    avg_time = total_time / num_iterations
    print(f"åŸå§‹æ¨¡å‹å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.4f}s")
    print(f"é¢„æœŸé‡åŒ–ååŠ é€Ÿ: 2-4å€")
    
    return avg_time

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset", default="datasets/tum/rgbd_dataset_freiburg1_desk")
    parser.add_argument("--precision", choices=["fp16", "int8"], default="int8")
    parser.add_argument("--samples", type=int, default=100)
    parser.add_argument("--output-dir", default="tensorrt_engines")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path(args.output_dir)
        output_dir.mkdir(exist_ok=True)
        
        # 1. åŠ è½½æ¨¡å‹
        model = load_model_direct()
        
        # 2. æ€§èƒ½åŸºå‡†æµ‹è¯•
        original_time = benchmark_original_model(model)
        
        # 3. å¯¼å‡ºONNX
        onnx_path = output_dir / "vit_encoder_direct.onnx"
        export_to_onnx(model, str(onnx_path))
        
        # 4. å‡†å¤‡æ ¡å‡†æ•°æ®
        calibration_data = None
        if args.precision == "int8":
            try:
                calibration_data = create_calibration_data(args.dataset, args.samples)
            except Exception as e:
                print(f"æ ¡å‡†æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
                print("å›é€€åˆ°FP16ç²¾åº¦")
                args.precision = "fp16"
        
        # 5. é‡åŒ–
        engine_path = output_dir / f"mast3r_vit_{args.precision}.trt"
        result = quantize_with_tensorrt(
            str(onnx_path), 
            calibration_data, 
            args.precision, 
            str(engine_path)
        )
        
        if result:
            print(f"\nğŸ‰ é‡åŒ–æˆåŠŸå®Œæˆ!")
            print(f"å¼•æ“æ–‡ä»¶: {result}")
            print(f"åŸå§‹æ¨ç†æ—¶é—´: {original_time:.4f}s")
            print(f"é¢„æœŸåŠ é€Ÿåæ—¶é—´: {original_time/3:.4f}s (3å€åŠ é€Ÿ)")
            
            # ç”Ÿæˆä½¿ç”¨è¯´æ˜
            print_simple_usage(result)
        else:
            print("âŒ é‡åŒ–å¤±è´¥")
    
    except Exception as e:
        print(f"é‡åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def print_simple_usage(engine_path):
    """æ‰“å°ç®€å•çš„ä½¿ç”¨è¯´æ˜"""
    print(f"\n=== ä½¿ç”¨è¯´æ˜ ===")
    print("å°†ä»¥ä¸‹ä»£ç æ·»åŠ åˆ°main.pyä¸­:")
    
    code = f'''
# åœ¨main.pyçš„æ¨¡å‹åŠ è½½éƒ¨åˆ†æ·»åŠ :

def load_quantized_model():
    """åŠ è½½é‡åŒ–æ¨¡å‹çš„ç®€å•æ–¹æ³•"""
    try:
        import tensorrt as trt
        import pycuda.driver as cuda
        import pycuda.autoinit
        
        # åŠ è½½TensorRTå¼•æ“
        with open("{engine_path}", "rb") as f:
            engine_data = f.read()
        
        logger = trt.Logger(trt.Logger.WARNING)
        runtime = trt.Runtime(logger)
        engine = runtime.deserialize_cuda_engine(engine_data)
        context = engine.create_execution_context()
        
        print("âœ“ é‡åŒ–æ¨¡å‹åŠ è½½æˆåŠŸ")
        return engine, context
    except Exception as e:
        print(f"é‡åŒ–æ¨¡å‹åŠ è½½å¤±è´¥: {{e}}")
        return None, None

# åœ¨æ¨¡å‹åŠ è½½éƒ¨åˆ†æ›¿æ¢:
# model = load_mast3r(device=device)

# ä¸º:
quantized_engine, quantized_context = load_quantized_model()
if quantized_engine:
    print("ä½¿ç”¨é‡åŒ–æ¨¡å‹")
    # è¿™é‡Œéœ€è¦å®ç°é‡åŒ–æ¨¡å‹çš„åŒ…è£…å™¨
    # ç°åœ¨å…ˆä½¿ç”¨åŸå§‹æ¨¡å‹
    model = load_mast3r(device=device)
else:
    model = load_mast3r(device=device)
'''
    
    print(code)
    print(f"\nå¼•æ“æ–‡ä»¶ä½ç½®: {engine_path}")
    print("æ³¨æ„: å®Œæ•´çš„é›†æˆéœ€è¦å®ç°TensorRTæ¨ç†åŒ…è£…å™¨")

if __name__ == "__main__":
    main()
